{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0f7d58",
   "metadata": {},
   "source": [
    "## 文本分块（Text Chunking）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d41f7",
   "metadata": {},
   "source": [
    "### 1. 文本提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e6471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 22\n",
      "First page text:\n",
      "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\n",
      "Reinforcement Learning\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.\n",
      "DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without super-\n",
      "vised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.\n",
      "Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing\n",
      "reasoning behaviors. However, it encounters challenges such as poor readability, and language\n",
      "mixing. To address these issues and further enhance reasoning performance, we introduce\n",
      "DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-\n",
      "R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the\n",
      "research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models\n",
      "(1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based o...\n"
     ]
    }
   ],
   "source": [
    "import pypdf\n",
    "\n",
    "pdfreader = pypdf.PdfReader('../docs/deepseek-r1.pdf')\n",
    "num_pages = len(pdfreader.pages)\n",
    "print(f'Number of pages: {num_pages}')\n",
    "\n",
    "page = pdfreader.pages[0]\n",
    "text = page.extract_text()\n",
    "print(f'First page text:\\n{text[:1000]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd993fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pages text:\n",
      "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\n",
      "Reinforcement Learning\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.\n",
      "DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without super-\n",
      "vised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.\n",
      "Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing\n",
      "reasoning behaviors. However, it encounters challenges such as poor readability, and language\n",
      "mixing. To address these issues and further enhance reasoning performance, we introduce\n",
      "DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-\n",
      "R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the\n",
      "research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models\n",
      "(1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based o...\n"
     ]
    }
   ],
   "source": [
    "all_pages_text = \"\".join([page.extract_text() for page in pdfreader.pages])\n",
    "print(f'All pages text:\\n{all_pages_text[:1000]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af9548",
   "metadata": {},
   "source": [
    "### 2. 文本切分\n",
    "\n",
    "将输入的文本分成多个块，每个文本块的长度大小比预设的chunk size小， 具体的切分流程包括：\n",
    "1. 将文本按照段落切分，一般以\"\\n\\n\\n\"为结尾\n",
    "2. 使用nltk sentence tokenizer将段落切分成句子\n",
    "3. 使用正则表达式将文本按标点符号划分，默认标点为\"[^,\\.;]+[,\\.;]?\"\n",
    "4. 如果有默认的空格`\" \"`，则继续做切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9970389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PARAGRAPH_SEP = \"\\n\\n\\n\"\n",
    "CHUNKING_REGEX = \"[^,.;。？！]+[,.;。？！]?|[,.;。？！]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a15616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional, Tuple\n",
    "\n",
    "def split_by_paragraph_sep(text: str, sep: str, keep_sep: bool = True) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits text by a separator.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to split.\n",
    "        sep (str): The separator to split on.\n",
    "        keep_sep (bool, optional): Whether to keep the separator in the output. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "       List[str]: A list of split strings.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if keep_sep:\n",
    "        parts = text.split(sep)\n",
    "        result = [sep + s if i > 0 else s for i, s in enumerate(parts)]\n",
    "        return [s for s in result if s]\n",
    "    else:\n",
    "        return text.split(sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd337b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = split_by_paragraph_sep(all_pages_text, DEFAULT_PARAGRAPH_SEP, keep_sep=True)\n",
    "# print(paragraphs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418087a0",
   "metadata": {},
   "source": [
    "使用NLTK的sentence tokenizer将段落切分成句子，注意在安装完NLTK后，需要下载popular数据包，否则会报错\n",
    "\n",
    "pip install --user -U nltk\n",
    "\n",
    "python -m nltk.downloader popular\n",
    "\n",
    "NLTK的sentence tokenizer能够确定文本块的起始标号[start_idx, end_idx]，该区间也被称为spans，因此可以用于切分文本块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2e19f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = PunktSentenceTokenizer()\n",
    "\n",
    "def split_by_sentence_tokenizer(text: str, tokenizer: PunktSentenceTokenizer) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits text by a sentence tokenizer.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to split.\n",
    "        tokenizer (PunktSentenceTokenizer): The tokenizer to use.\n",
    "\n",
    "    Returns:\n",
    "       List[str]: A list of split strings.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    spans = list(tokenizer.span_tokenize(text))\n",
    "    sentences = []\n",
    "    for i, span in enumerate(spans):\n",
    "        start = span[0]\n",
    "        if i < len(spans) - 1:\n",
    "            end = spans[i + 1][0]\n",
    "        else:\n",
    "            end = len(text)\n",
    "        sentences.append(text[start:end])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c85fe81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\n",
      "Reinforcement Learning\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.\n",
      "\n",
      "\n",
      "DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without super-\n",
      "vised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = split_by_sentence_tokenizer(paragraphs[0], tokenizer)\n",
    "print(sentences[0])\n",
    "print('\\n'+sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46c40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
